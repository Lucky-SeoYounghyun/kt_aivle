{"cells":[{"cell_type":"markdown","metadata":{"id":"CyurDtxqHT0o"},"source":["# **Use YOLO : Object Detection !**"]},{"cell_type":"markdown","metadata":{"id":"WE6nWiH8-i9q"},"source":["## 0.미션\n"]},{"cell_type":"markdown","metadata":{"id":"53bSTpVT-n_Y"},"source":["### (1) 미션1\n","여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 주어진 데이터셋은 2가지입니다. 해당 데이터셋의 압축 파일을 해제해야 합니다.\n","        1. [Face_Recognition_1](https://universe.roboflow.com/new-workspace-kuixc/face-recognition-dataset/dataset/1).zip\n","        2. [Face_Recognition_2](https://universe.roboflow.com/td-vgaen/test-uiodm/dataset/2).zip\n","        - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n","    - **여러분의 얼굴 이미지와 라벨링 작업까지 마친 파일 역시 데이터셋으로 압축하여 Google Colab에서 해제해주세요.**\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/detect/)\n","- 3) YAML 파일을 생성합니다.\n","    - 전처리까지 완료한 데이터셋의 구조를 YAML 파일에 저장합니다."]},{"cell_type":"markdown","metadata":{"id":"DBjsZP8C-2Ra"},"source":["### (2) 미션2\n","데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO 모델 링크](https://docs.ultralytics.com/tasks/detect/)\n","- 2) 선택한 UltraLytics YOLO 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"WkDv7UfdYOgg"},"source":["## 1.환경설정"]},{"cell_type":"markdown","metadata":{"id":"mIxbiQ8wYOcy"},"source":["* 세부 요구사항\n","    - 경로 설정 : 구글콜랩\n","        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n","        * 데이터 파일을 복사해 넣습니다.\n","        * 필요하다고 판단되는 라이브러리를 추가하세요."]},{"cell_type":"markdown","metadata":{"id":"XIjpXC-xYHh3"},"source":["### (1) 경로 설정"]},{"cell_type":"markdown","metadata":{"id":"m6qgvZMSYcoX"},"source":["* 구글 드라이브 연결"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imfft4dGGJ2E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730406778697,"user_tz":-540,"elapsed":19418,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"8112c709-8de0-40f4-aa43-df93317ed21b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPngJ_nwZPRC"},"outputs":[],"source":["path = '/content/drive/MyDrive/project4'"]},{"cell_type":"markdown","metadata":{"id":"SNEKwf_LY0JB"},"source":["### (2) 라이브러리 설치 및 불러오기"]},{"cell_type":"markdown","metadata":{"id":"xPwDW6e_Y0Fa"},"source":["* 라이브러리 로딩"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4dS7tW-Zwrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730406786671,"user_tz":-540,"elapsed":7976,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"a64b2c01-2961-4eea-ba10-501b70fd51bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.26-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.26-py3-none-any.whl (878 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.26 ultralytics-thop-2.0.10\n"]}],"source":["## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n","!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"Eg0gCl9Yatak"},"source":["## 2.미션1"]},{"cell_type":"markdown","metadata":{"id":"hPvTHwTmbKR5"},"source":["여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 주어진 데이터셋은 2가지입니다. 해당 데이터셋의 압축 파일을 해제해야 합니다.\n","        1. [Face_Recognition_1](https://universe.roboflow.com/new-workspace-kuixc/face-recognition-dataset/dataset/1).zip\n","        2. [Face_Recognition_2](https://universe.roboflow.com/td-vgaen/test-uiodm/dataset/2).zip\n","        - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n","    - **여러분의 얼굴 이미지와 라벨링 작업까지 마친 파일 역시 데이터셋으로 압축하여 Google Colab에서 해제해주세요.**\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/detect/)\n","- 3) YAML 파일을 생성합니다.\n","    - 전처리까지 완료한 데이터셋의 구조를 YAML 파일에 저장합니다."]},{"cell_type":"markdown","metadata":{"id":"6rXSONrsatd5"},"source":["### (1) 데이터셋 불러오기"]},{"cell_type":"markdown","metadata":{"id":"VXLqxwNaathI"},"source":["* **세부 요구사항**\n","    - 데이터셋을 불러옵니다.\n","        - 주어진 데이터셋은 2가지입니다. 해당 데이터셋의 압축 파일을 해제해야 합니다.\n","            1. [Face_Recognition_1](https://universe.roboflow.com/new-workspace-kuixc/face-recognition-dataset/dataset/1).zip\n","            2. [Face_Recognition_2](https://universe.roboflow.com/td-vgaen/test-uiodm/dataset/2).zip\n","            - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n","        - **여러분의 얼굴 이미지와 라벨링 작업까지 마친 파일 역시 데이터셋으로 압축하여 Google Colab에서 해제해주세요.**\n","    - 데이터셋 압축 파일을 가급적 **Colab에 폴더를 생성한 후 해제**하세요.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, zipfile"]},{"cell_type":"markdown","metadata":{"id":"6OntGw5H-C3q"},"source":["#### 1) 데이터셋 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIqkusHkOnSo"},"outputs":[],"source":["import os\n","import zipfile\n","import cv2\n"]},{"cell_type":"code","source":["def extract_zip_to_folder(zip_path, extract_folder_name):\n","    \"\"\"\n","    주어진 ZIP 파일 경로를 '/content/image_data/' 경로에 압축 해제하는 함수.\n","\n","    Args:\n","    zip_path (str): 압축 해제할 ZIP 파일의 전체 경로.\n","    \"\"\"\n","    # 기본 경로 설정\n","    zip_file_name = os.path.basename(zip_path)\n","    extract_folder = f'/content/image_data/{extract_folder_name}'\n","\n","    # 지정된 경로에 폴더가 없을 때 생성\n","    if not os.path.exists(extract_folder):\n","        os.makedirs(extract_folder)\n","        print(f\"{extract_folder} 폴더를 생성했습니다.\")\n","\n","    # ZIP 파일 압축 해제\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        for f in zip_ref.namelist():\n","            # 디렉토리가 아닌 모든 파일에 대해 처리\n","            if not f.endswith('/'):\n","                # 파일의 전체 경로 생성\n","                d_path = os.path.join(extract_folder, f)\n","\n","                # 파일의 디렉토리 경로 생성 (하위 디렉토리 포함)\n","                os.makedirs(os.path.dirname(d_path), exist_ok=True)\n","\n","                # 파일 추출\n","                with zip_ref.open(f) as source, open(d_path, 'wb') as target:\n","                    target.write(source.read())\n","\n","    print(f\"{zip_path}의 압축을 {extract_folder}에 해제했습니다.\")"],"metadata":{"id":"Pm_kuG6AaXic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import cv2\n","\n","# def crop_images_to_center(src_folder, crop_size=(640, 640)):\n","#     \"\"\"\n","#     주어진 폴더와 모든 하위 폴더 내의 .jpg 이미지를 중심을 기준으로 주어진 크기로 크롭하여 원본 파일에 덮어쓰는 함수.\n","\n","#     Args:\n","#     src_folder (str): 원본 이미지 폴더 경로.\n","#     crop_size (tuple): 크롭할 이미지의 크기 (너비, 높이).\n","#     \"\"\"\n","#     # 폴더 내 모든 파일 탐색\n","#     for root, _, files in os.walk(src_folder):\n","#         for img_file in files:\n","#             if img_file.endswith('.jpg'):\n","#                 img_path = os.path.join(root, img_file)\n","#                 img = cv2.imread(img_path)\n","\n","#                 if img is not None:\n","#                     h, w, _ = img.shape\n","#                     crop_w, crop_h = crop_size\n","\n","#                     # 중심 좌표 계산\n","#                     center_x, center_y = w // 2, h // 2\n","\n","#                     # 크롭 영역 계산\n","#                     x1 = max(center_x - crop_w // 2, 0)\n","#                     y1 = max(center_y - crop_h // 2, 0)\n","#                     x2 = min(center_x + crop_w // 2, w)\n","#                     y2 = min(center_y + crop_h // 2, h)\n","\n","#                     # 크롭된 이미지 생성\n","#                     cropped_img = img[y1:y2, x1:x2]\n","\n","#                     # 크롭된 이미지 저장 (덮어쓰기)\n","#                     cv2.imwrite(img_path, cropped_img)\n","\n","#     print(f\"{src_folder} 내의 모든 이미지를 {crop_size} 크기로 크롭하여 덮어썼습니다.\")\n","\n","import os\n","import cv2\n","\n","def crop_and_resize_images(src_folder, crop_size=(480, 480), target_size=(640, 640)):\n","    \"\"\"\n","    주어진 폴더 내 모든 .jpg 이미지를 중심을 기준으로 크롭하고, 지정된 크기로 확대하여 원본 파일에 덮어쓰는 함수.\n","\n","    Args:\n","    src_folder (str): 원본 이미지 폴더 경로.\n","    crop_size (tuple): 중심을 기준으로 크롭할 이미지의 크기 (너비, 높이).\n","    target_size (tuple): 크롭 후 리사이즈할 이미지의 최종 크기 (너비, 높이).\n","    \"\"\"\n","    crop_w, crop_h = crop_size\n","    target_w, target_h = target_size\n","\n","    # 폴더 내 모든 파일 탐색\n","    for root, _, files in os.walk(src_folder):\n","        for img_file in files:\n","            if img_file.endswith('.jpg'):\n","                img_path = os.path.join(root, img_file)\n","                img = cv2.imread(img_path)\n","\n","                if img is not None:\n","                    h, w, _ = img.shape\n","\n","                    # 중심 좌표 계산\n","                    center_x, center_y = w // 2, h // 2\n","\n","                    # 크롭 영역 계산\n","                    x1 = max(center_x - crop_w // 2, 0)\n","                    y1 = max(center_y - crop_h // 2, 0)\n","                    x2 = min(center_x + crop_w // 2, w)\n","                    y2 = min(center_y + crop_h // 2, h)\n","\n","                    # 크롭된 이미지 생성\n","                    cropped_img = img[y1:y2, x1:x2]\n","\n","                    # 480x480으로 잘린 이미지를 640x640으로 리사이즈\n","                    resized_img = cv2.resize(cropped_img, (target_w, target_h))\n","\n","                    # 리사이즈된 이미지 저장 (덮어쓰기)\n","                    cv2.imwrite(img_path, resized_img)\n","\n","    print(f\"{src_folder} 내의 모든 이미지를 {crop_size}로 크롭하고 {target_size}로 리사이즈하여 덮어썼습니다.\")\n"],"metadata":{"id":"4qI8Echt-ous"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","def adjust_labels_for_resize(label_path, scale_factor):\n","    \"\"\"\n","    레이블 파일의 바운딩 박스 좌표를 이미지 리사이즈 비율에 맞춰 변경하는 함수.\n","    가로 방향만 조정하고 유효성 검사를 수행합니다.\n","\n","    Args:\n","    label_path (str): 레이블 파일 경로.\n","    scale_factor (float): 이미지 확대 비율.\n","    \"\"\"\n","    with open(label_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    new_lines = []\n","    for line in lines:\n","        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n","\n","        # 가로 방향 비율 적용\n","        x_center -= 0.025\n","        width *= scale_factor\n","\n","        # 유효성 검사: 1보다 크면 1로 제한\n","        x_center = min(x_center, 1.0)\n","        width = min(width, 1.0)\n","\n","        new_lines.append(f\"{int(class_id)} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n","\n","    # 레이블 파일 덮어쓰기\n","    with open(label_path, 'w') as f:\n","        f.writelines(new_lines)\n","\n","def adjust_all_labels_in_folder(src_folder, scale_factor=640/480):\n","    \"\"\"\n","    주어진 폴더 내의 모든 .txt 파일에 대해 레이블 좌표를 조정하는 함수.\n","\n","    Args:\n","    src_folder (str): 레이블 파일이 있는 폴더 경로.\n","    scale_factor (float): 이미지 가로 방향 확대 비율.\n","    \"\"\"\n","    for root, _, files in os.walk(src_folder):\n","        for file in files:\n","            if file.endswith('.txt'):\n","                label_path = os.path.join(root, file)\n","                adjust_labels_for_resize(label_path, scale_factor)"],"metadata":{"id":"OujSgWUxNDEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 내 얼굴 데이터\n","me_path = os.path.join(path, 'Datasets/me.zip')\n","# me = os.path.join(path, 'Datasets/auto_labels_test.zip')\n","me_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"O0tRgVFrWKGc","executionInfo":{"status":"ok","timestamp":1730406787473,"user_tz":-540,"elapsed":4,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"0c6d3e16-66ea-46ff-ee3f-c1de8c22a72d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/project4/Datasets/me.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["extract_zip_to_folder(me_path, 'me')"],"metadata":{"id":"rg7zPiojXGLk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730406822864,"user_tz":-540,"elapsed":35394,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"d738c5d8-e5b8-40ce-bb92-461324f46e12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/me 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/me.zip의 압축을 /content/image_data/me에 해제했습니다.\n"]}]},{"cell_type":"code","source":["not_me_01_path = os.path.join(path, 'Datasets/YOLO/Face_Recognition_1.zip')\n","not_me_01_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9OantsVFWJ_U","executionInfo":{"status":"ok","timestamp":1730406822864,"user_tz":-540,"elapsed":4,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"82ea29c7-c847-4d53-b4ea-b9241c82a76c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/project4/Datasets/YOLO/Face_Recognition_1.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["extract_zip_to_folder(not_me_01_path, 'not_me_01')"],"metadata":{"id":"WPn8a19wXIPk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730406833746,"user_tz":-540,"elapsed":10885,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"e549f190-f76e-4f44-a921-a97f3c6d8ad8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/not_me_01 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/YOLO/Face_Recognition_1.zip의 압축을 /content/image_data/not_me_01에 해제했습니다.\n"]}]},{"cell_type":"code","source":["not_me_02_path = os.path.join(path, 'Datasets/YOLO/Face_Recognition_2.zip')\n","not_me_02_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"-oFV1NREWJ0F","executionInfo":{"status":"ok","timestamp":1730406833746,"user_tz":-540,"elapsed":3,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"771bb8fb-43d5-464f-9b8f-60ca6b509e57"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/project4/Datasets/YOLO/Face_Recognition_2.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["extract_zip_to_folder(not_me_02_path, 'not_me_02')"],"metadata":{"id":"naDKYw6BXWvl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730406839766,"user_tz":-540,"elapsed":6022,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"f4aa5ea3-a446-45f6-a115-0a657ff5e234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/not_me_02 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/YOLO/Face_Recognition_2.zip의 압축을 /content/image_data/not_me_02에 해제했습니다.\n"]}]},{"cell_type":"code","source":["jihong_path = os.path.join(path, 'Datasets/jihong.zip')\n","\n","extract_zip_to_folder(jihong_path, 'jihong')\n","\n","src_folder = '/content/image_data/jihong'\n","crop_and_resize_images(src_folder)\n","\n","src_folder = '/content/image_data/jihong'\n","adjust_all_labels_in_folder(src_folder, scale_factor=640/480)"],"metadata":{"id":"qpRzI6ozZm08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730406928967,"user_tz":-540,"elapsed":89202,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"c670d260-357d-4b6f-e707-70c90b896d12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/jihong 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/jihong.zip의 압축을 /content/image_data/jihong에 해제했습니다.\n","/content/image_data/jihong 내의 모든 이미지를 (480, 480)로 크롭하고 (640, 640)로 리사이즈하여 덮어썼습니다.\n"]}]},{"cell_type":"code","source":["hyewon_path = os.path.join(path, 'Datasets/hyewon.zip')\n","\n","extract_zip_to_folder(hyewon_path, 'hyewon')\n","\n","src_folder = '/content/image_data/hyewon'\n","crop_and_resize_images(src_folder)\n","\n","src_folder = '/content/image_data/hyewon'\n","adjust_all_labels_in_folder(src_folder, scale_factor=640/480)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"by-divgCbSfM","executionInfo":{"status":"ok","timestamp":1730407005281,"user_tz":-540,"elapsed":76317,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"93a8c051-ab07-4d20-934f-e03d9c8b69f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/hyewon 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/hyewon.zip의 압축을 /content/image_data/hyewon에 해제했습니다.\n","/content/image_data/hyewon 내의 모든 이미지를 (480, 480)로 크롭하고 (640, 640)로 리사이즈하여 덮어썼습니다.\n"]}]},{"cell_type":"code","source":["hyeongu_path = os.path.join(path, 'Datasets/hyeongu.zip')\n","\n","extract_zip_to_folder(hyeongu_path, 'hyeongu')\n","src_folder = '/content/image_data/hyeongu'\n","crop_and_resize_images(src_folder)\n","\n","src_folder = '/content/image_data/hyeongu'\n","adjust_all_labels_in_folder(src_folder, scale_factor=640/480)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbMGg_HabT6O","executionInfo":{"status":"ok","timestamp":1730407099073,"user_tz":-540,"elapsed":93794,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"9167f2cd-5632-4725-e3d4-082de63db1f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/hyeongu 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/hyeongu.zip의 압축을 /content/image_data/hyeongu에 해제했습니다.\n","/content/image_data/hyeongu 내의 모든 이미지를 (480, 480)로 크롭하고 (640, 640)로 리사이즈하여 덮어썼습니다.\n"]}]},{"cell_type":"code","source":["chaerim_path = os.path.join(path, 'Datasets/chaerim.zip')\n","\n","extract_zip_to_folder(chaerim_path ,'chaerim')\n","src_folder = '/content/image_data/chaerim'\n","crop_and_resize_images(src_folder)\n","\n","src_folder = '/content/image_data/chaerim'\n","adjust_all_labels_in_folder(src_folder, scale_factor=640/480)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAshafNObaON","executionInfo":{"status":"ok","timestamp":1730407190675,"user_tz":-540,"elapsed":91604,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"a6cb78d8-dd25-46f6-db84-8b0708ea7ddb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_data/chaerim 폴더를 생성했습니다.\n","/content/drive/MyDrive/project4/Datasets/chaerim.zip의 압축을 /content/image_data/chaerim에 해제했습니다.\n","/content/image_data/chaerim 내의 모든 이미지를 (480, 480)로 크롭하고 (640, 640)로 리사이즈하여 덮어썼습니다.\n"]}]},{"cell_type":"markdown","metadata":{"id":"G-TovD9FLCCL"},"source":["### (2) 데이터셋 전처리"]},{"cell_type":"markdown","metadata":{"id":"tJPBtHv8LCCL"},"source":["* **세부 요구사항**\n","    - Label 파일, 즉 txt 파일의 클래스를 수정하셔야 합니다.\n","        - 여러 클래스로 구분되어 있는 것을 하나로 통일해주세요.\n","        - 이것은 **다른 사람의 얼굴**에 대해 전처리하는 작업입니다.\n","    - UltraLytics YOLO 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/detect/)\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, glob, random, shutil, numpy"]},{"cell_type":"markdown","metadata":{"id":"OuvkaiTYAfEB"},"source":["#### 1) Label 파일의 클래스 값 변경"]},{"cell_type":"code","source":["import random\n","import shutil\n","import os\n","import glob"],"metadata":{"id":"ZEakY6TFo8HI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dj_jpKOtOpcS"},"outputs":[],"source":["# 원본 폴더 경로\n","source_folders = ['/content/image_data/not_me_01', '/content/image_data/not_me_02']\n","# 새롭게 결합할 폴더 경로\n","destination_folder = '/content/image_data/not_me'\n","\n","# not_me 폴더 생성\n","if not os.path.exists(destination_folder):\n","    os.makedirs(destination_folder)\n","\n","# 폴더를 순회하며 not_me 폴더에 병합\n","for source_folder in source_folders:\n","    for root, dirs, files in os.walk(source_folder):\n","        for file in files:\n","            # images 및 labels 폴더 구조 유지\n","            rel_path = os.path.relpath(root, source_folder)\n","            dest_path = os.path.join(destination_folder, rel_path)\n","            os.makedirs(dest_path, exist_ok=True)\n","\n","            # .txt 파일 처리\n","            if file.endswith('.txt'):\n","                source_file = os.path.join(root, file)\n","                dest_file = os.path.join(dest_path, file)\n","\n","                with open(source_file, 'r') as f:\n","                    lines = f.readlines()\n","\n","                # 중복 라벨 제거 및 첫 번째 숫자를 1로 변경\n","                unique_lines = set()  # 중복을 제거하기 위한 집합\n","                with open(dest_file, 'w') as f:\n","                    for line in lines:\n","                        parts = line.split()\n","                        parts[0] = '1'  # 첫 번째 숫자를 1로 변경\n","                        new_line = \" \".join(parts)\n","\n","                        # 중복되지 않은 경우만 기록\n","                        if new_line not in unique_lines:\n","                            unique_lines.add(new_line)\n","                            f.write(new_line + '\\n')\n","            else:\n","                # .txt 외의 파일은 그대로 복사\n","                shutil.copy2(os.path.join(root, file), dest_path)"]},{"cell_type":"code","source":["train_folder = '/content/image_data/not_me/test/images'\n","\n","# train 폴더 안의 파일 수 계산\n","file_count = len([f for f in os.listdir(train_folder) if os.path.isfile(os.path.join(train_folder, f))])\n","\n","print(f\"'train' 폴더 안의 파일 수: {file_count}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEoeJMHKqEC7","executionInfo":{"status":"ok","timestamp":1730407217492,"user_tz":-540,"elapsed":3,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"143ba788-7696-4899-e6e2-4e7a72a74206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'train' 폴더 안의 파일 수: 753\n"]}]},{"cell_type":"markdown","metadata":{"id":"-_MF4zCRie5X"},"source":["#### 2) 모델이 요하는 구조의 폴더 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dyzTbiZ3Qad"},"outputs":[],"source":["# 원본 폴더 경로\n","not_me_folder = '/content/image_data/not_me'\n","me_folder = '/content/image_data/me'\n","jihong_folder = '/content/image_data/jihong'\n","hyewon_folder = '/content/image_data/hyewon'\n","hyeongu_folder = '/content/image_data/hyeongu'\n","chaerim_folder = '/content/image_data/chaerim'\n","\n","# Datasets 폴더 경로 및 하위 폴더 생성\n","datasets_folder = '/content/Datasets'\n","\n","# train, valid, test 폴더 생성 및 하위 images, labels 폴더 생성\n","for split in ['train', 'valid', 'test']:\n","    os.makedirs(os.path.join(datasets_folder, split, 'images'), exist_ok=True)\n","    os.makedirs(os.path.join(datasets_folder, split, 'labels'), exist_ok=True)\n","\n","# 파일 복사 함수\n","def copy_files(src_folder, dest_folder_images, dest_folder_labels):\n","    for root, dirs, files in os.walk(src_folder):\n","        for file in files:\n","            src_path = os.path.join(root, file)\n","            if file.endswith('.jpg'):\n","                dest_path = os.path.join(dest_folder_images, file)\n","            elif file.endswith('.txt'):\n","                dest_path = os.path.join(dest_folder_labels, file)\n","            else:\n","                continue\n","            shutil.copy2(src_path, dest_path)\n","\n","# 각 split 폴더에서 not_me와 me 파일을 통합하여 복사\n","for split in ['train', 'valid', 'test']:\n","    # 통합 대상 폴더 경로 설정\n","    dest_images = os.path.join(datasets_folder, split, 'images')\n","    dest_labels = os.path.join(datasets_folder, split, 'labels')\n","\n","    # not_me 폴더에서 이미지 및 라벨 복사\n","    not_me_src = os.path.join(not_me_folder, split)\n","    copy_files(not_me_src, dest_images, dest_labels)\n","\n","    # me 폴더에서 이미지 및 라벨 복사\n","    me_src = os.path.join(me_folder, split)\n","    copy_files(me_src, dest_images, dest_labels)\n","\n","    # jihong 폴더에서 이미지 및 라벨 복사\n","    jihong_src = os.path.join(jihong_folder, split)\n","    copy_files(jihong_src, dest_images, dest_labels)\n","\n","    # me 폴더에서 이미지 및 라벨 복사\n","    hyewon_src = os.path.join(hyewon_folder, split)\n","    copy_files(hyewon_src, dest_images, dest_labels)\n","\n","    # me 폴더에서 이미지 및 라벨 복사\n","    hyeongu_src = os.path.join(hyeongu_folder, split)\n","    copy_files(hyeongu_src, dest_images, dest_labels)\n","\n","    # me 폴더에서 이미지 및 라벨 복사\n","    chaerim_src = os.path.join(chaerim_folder, split)\n","    copy_files(chaerim_src, dest_images, dest_labels)"]},{"cell_type":"code","source":["train_folder = '/content/Datasets/test/images'\n","\n","# train 폴더 안의 파일 수 계산\n","file_count = len([f for f in os.listdir(train_folder) if os.path.isfile(os.path.join(train_folder, f))])\n","\n","print(f\"'test' 폴더 안의 파일 수: {file_count}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SppaYqK_5hh3","executionInfo":{"status":"ok","timestamp":1730407815647,"user_tz":-540,"elapsed":351,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"b318576c-f3fc-49f9-ff81-cac9734edf3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'train' 폴더 안의 파일 수: 5595\n"]}]},{"cell_type":"markdown","metadata":{"id":"wZPds1GraeJ3"},"source":["#### 3) 각 폴더에 데이터 옮기기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QL3N_62m3QoM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BsOt56PB8uMZ"},"source":["### (3) YAML 파일 생성"]},{"cell_type":"markdown","metadata":{"id":"aESOaV9G8uSm"},"source":["* **세부 요구사항**\n","    - 데이터셋의 구조를 YAML 파일에 작성하여 저장합니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - yaml(pyyaml)"]},{"cell_type":"markdown","metadata":{"id":"fGjFZc5u-IFb"},"source":["#### 1) 데이터셋 구조 코드 작성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BvxaQw_f8uW7"},"outputs":[],"source":["dataset_structure = {\n","    'train': '/content/Datasets/train/images/',\n","    'val': '/content/Datasets/valid/images/',\n","    'test': '/content/Datasets/test/images/',\n","    'nc': 6,\n","    'names': {\n","        0: 'younghyun',\n","        1: 'not_me',\n","        4: 'hyeongu',\n","        3: 'chaerim',\n","        2: 'hyewon',\n","        5: 'jihong'\n","    }\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"rcyi7Giy-GTa"},"source":["#### 2) YAML 파일 작성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYXlSpMp8uaZ"},"outputs":[],"source":["import yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-s7lZAiL-Z2Q"},"outputs":[],"source":["# YAML 파일 경로\n","yaml_file_path = '/content/Datasets/dataset_structure.yaml'\n","\n","# YAML 파일로 데이터셋 구조 저장\n","with open(yaml_file_path, 'w') as yaml_file:\n","    yaml.dump(dataset_structure, yaml_file, default_flow_style=False, sort_keys=False)"]},{"cell_type":"markdown","metadata":{"id":"w59u5Dtnrh5h"},"source":["## 3.미션2"]},{"cell_type":"markdown","metadata":{"id":"JHu91EoOrh2Q"},"source":["데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO 모델 링크](https://docs.ultralytics.com/tasks/detect/)\n","- 2) 선택한 UltraLytics YOLO 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"AygPItZba0TI"},"source":["#### (1) UltraLytics YOLO 모델 선택"]},{"cell_type":"markdown","metadata":{"id":"E7zOy5GfbMTR"},"source":["* **세부 요구사항**\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO 모델 링크](https://docs.ultralytics.com/tasks/detect/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULEjDkdUGhCz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730407934086,"user_tz":-540,"elapsed":10817,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"94e85390-5670-413b-db34-48ce9c77ec29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"source":["from ultralytics import YOLO"]},{"cell_type":"code","source":["model = YOLO(\"yolo11n.pt\")"],"metadata":{"id":"qUYXrvK9xYgU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730407934622,"user_tz":-540,"elapsed":537,"user":{"displayName":"서영현","userId":"09271535808037779652"}},"outputId":"84fdec9a-4df8-45c7-9be0-fc0be9fbf560"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 43.2MB/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"X7rqg7bda6Uz"},"source":["#### (2) UltraLytics YOLO 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"48UKFtS6bc9b"},"source":["* **세부 요구사항**\n","    - 선택한 UltraLytics YOLO 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"891Qn60yGhCz","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3d9c7c66-df29-47f6-8c03-859f3b06cded","executionInfo":{"status":"error","timestamp":1730408397348,"user_tz":-540,"elapsed":462727,"user":{"displayName":"서영현","userId":"09271535808037779652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.26 🚀 Python-3.10.12 torch-2.5.0+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/Datasets/dataset_structure.yaml, epochs=10, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.001, warmup_epochs=5, warmup_momentum=0.8, warmup_bias_lr=0.1, box=5.0, cls=0.3, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.1, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 15.0MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=6\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    431842  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n","YOLO11n summary: 319 layers, 2,591,010 parameters, 2,590,994 gradients, 6.4 GFLOPs\n","\n","Transferred 448/499 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.23.dfl.conv.weight'\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Datasets/train/labels... 56241 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56241/56241 [03:10<00:00, 295.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Datasets/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0m96.5GB RAM required to cache images with 50% safety margin but only 10.7/12.7GB available, not caching images ⚠️\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Datasets/valid/labels... 11186 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11186/11186 [00:29<00:00, 379.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Datasets/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0m19.2GB RAM required to cache images with 50% safety margin but only 10.7/12.7GB available, not caching images ⚠️\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.001), 87 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/10         0G      1.134      2.849      2.179         16        640:   0%|          | 12/3516 [03:22<16:23:55, 16.85s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-8ae4411f04cc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# results = model.train(data=\"/content/Datasets/dataset_structure.yaml\", epochs=5, imgsz=480, scale=0.4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/Datasets/dataset_structure.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Training path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# results = model.train(data=\"/content/Datasets/dataset_structure.yaml\", epochs=5, imgsz=480, scale=0.4)\n","results = model.train(data=\"/content/Datasets/dataset_structure.yaml\", epochs=10, imgsz=640, patience = 10, weight_decay\t= 0.001, cache = True, warmup_epochs=5, lrf=0.1, label_smoothing=0.1, box=5.0, cls=0.3, dropout=0.3)"]},{"cell_type":"markdown","metadata":{"id":"UsxBhoAubn2u"},"source":["#### (3) UltraLytics YOLO 추론"]},{"cell_type":"markdown","metadata":{"id":"wPtTHcnbbn2u"},"source":["* **세부 요구사항**\n","    - 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ffQ725eGhC0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2ytKJsOUGhC0"},"source":["#### (4) UltraLytics YOLO 모델 저장"]},{"cell_type":"markdown","metadata":{"id":"VkC4WP-8cA7g"},"source":["* **세부 요구사항**\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqGS418hRvMz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730349395150,"user_tz":-540,"elapsed":1704,"user":{"displayName":"서영현","userId":"02755858754001862721"}},"outputId":"99ead034-eaa0-47d0-ae5a-fb13c81bc95f"},"outputs":[{"output_type":"stream","name":"stdout","text":["완료\n"]}],"source":["drive_save_path = '/content/drive/MyDrive/project4/best_model_weights_day_3_ver2'\n","os.makedirs(drive_save_path, exist_ok=True)\n","\n","\n","best_model_paths = glob.glob('/content/runs/**/weights/best.pt', recursive=True)\n","\n","if best_model_paths:\n","    latest_best_model_path = best_model_paths[-1]\n","    shutil.copy(latest_best_model_path, drive_save_path)\n","    print(\"완료\")\n","else:\n","    print(\"없음\")"]},{"cell_type":"code","source":[],"metadata":{"id":"aXHLLEXB-qRQ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}